{"Round 1": {"Accuracy/Testing Accuracy": 0.012987012987012988, "Loss/Testing Loss": 4.517292786883069, "mean_training_loss": 1.4350043890115463}, "Round 2": {"Accuracy/Testing Accuracy": 0.05844155844155844, "Loss/Testing Loss": 4.1255080706113345, "mean_training_loss": 1.098579098172486}, "Round 3": {"Accuracy/Testing Accuracy": 0.17012987012987013, "Loss/Testing Loss": 3.652307877602515, "mean_training_loss": 0.8764217624342757}, "Round 4": {"Accuracy/Testing Accuracy": 0.2701298701298701, "Loss/Testing Loss": 3.126492611154333, "mean_training_loss": 0.7569706996793256}, "Round 5": {"Accuracy/Testing Accuracy": 0.32987012987012987, "Loss/Testing Loss": 2.7395758672194046, "mean_training_loss": 0.5177876113864937}, "Round 6": {"Accuracy/Testing Accuracy": 0.38441558441558443, "Loss/Testing Loss": 2.4195379368670573, "mean_training_loss": 0.7441578185984068}, "Round 7": {"Accuracy/Testing Accuracy": 0.44285714285714284, "Loss/Testing Loss": 2.138935577714598, "mean_training_loss": 0.3405524997369331}, "Round 8": {"Accuracy/Testing Accuracy": 0.4961038961038961, "Loss/Testing Loss": 1.8666787803947151, "mean_training_loss": 0.3484612163289317}, "Round 9": {"Accuracy/Testing Accuracy": 0.535064935064935, "Loss/Testing Loss": 1.7376666487037362, "mean_training_loss": 0.47796796499328176}, "Round 10": {"Accuracy/Testing Accuracy": 0.5558441558441558, "Loss/Testing Loss": 1.6020755074240944, "mean_training_loss": 0.26683049979619683}, "Round 11": {"Accuracy/Testing Accuracy": 0.5831168831168831, "Loss/Testing Loss": 1.475134268364349, "mean_training_loss": 0.26358751511201267}, "Round 12": {"Accuracy/Testing Accuracy": 0.6038961038961039, "Loss/Testing Loss": 1.4173298572565054, "mean_training_loss": 0.1641529097579993}, "Round 13": {"Accuracy/Testing Accuracy": 0.6272727272727273, "Loss/Testing Loss": 1.3191082539496484, "mean_training_loss": 0.17207220915704965}, "Round 14": {"Accuracy/Testing Accuracy": 0.6402597402597403, "Loss/Testing Loss": 1.2681474159290265, "mean_training_loss": 0.18508976025178153}, "Round 15": {"Accuracy/Testing Accuracy": 0.6571428571428571, "Loss/Testing Loss": 1.2355662658617095, "mean_training_loss": 0.23508774780978764}, "Round 16": {"Accuracy/Testing Accuracy": 0.6688311688311688, "Loss/Testing Loss": 1.1770786505240898, "mean_training_loss": 0.6286941969974175}, "Round 17": {"Accuracy/Testing Accuracy": 0.6844155844155844, "Loss/Testing Loss": 1.1749092897811493, "mean_training_loss": 0.1747232238378595}, "Round 18": {"Accuracy/Testing Accuracy": 0.6974025974025974, "Loss/Testing Loss": 1.1084475576103507, "mean_training_loss": 0.1265917857262221}, "Round 19": {"Accuracy/Testing Accuracy": 0.7168831168831169, "Loss/Testing Loss": 1.0647904199439209, "mean_training_loss": 0.43391126915812495}, "Round 20": {"Accuracy/Testing Accuracy": 0.6766233766233766, "Loss/Testing Loss": 1.1081142332646754, "mean_training_loss": 0.1770264629398783}, "Round 21": {"Accuracy/Testing Accuracy": 0.6883116883116883, "Loss/Testing Loss": 1.0671941079102554, "mean_training_loss": 0.06990418644621968}, "Round 22": {"Accuracy/Testing Accuracy": 0.6935064935064935, "Loss/Testing Loss": 1.0447706529072354, "mean_training_loss": 0.12594667386094277}, "Round 23": {"Accuracy/Testing Accuracy": 0.6935064935064935, "Loss/Testing Loss": 1.0214455903350532, "mean_training_loss": 0.0886894801321129}, "Round 24": {"Accuracy/Testing Accuracy": 0.7324675324675325, "Loss/Testing Loss": 0.9743706560754156, "mean_training_loss": 0.2594060457804624}, "Round 25": {"Accuracy/Testing Accuracy": 0.7168831168831169, "Loss/Testing Loss": 0.9772332782869215, "mean_training_loss": 0.10721354171295057}, "Round 26": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 0.9888151518710248, "mean_training_loss": 0.032877894782771665}, "Round 27": {"Accuracy/Testing Accuracy": 0.7090909090909091, "Loss/Testing Loss": 0.961370643547603, "mean_training_loss": 0.03354455014923587}, "Round 28": {"Accuracy/Testing Accuracy": 0.7142857142857143, "Loss/Testing Loss": 0.9223330304220125, "mean_training_loss": 0.021154762626974844}, "Round 29": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.8951270631381444, "mean_training_loss": 0.02116227538945774}, "Round 30": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.8984616330691746, "mean_training_loss": 0.058893589861691}, "Round 31": {"Accuracy/Testing Accuracy": 0.7337662337662337, "Loss/Testing Loss": 0.8807445745963555, "mean_training_loss": 0.05767089567485857}, "Round 32": {"Accuracy/Testing Accuracy": 0.7246753246753247, "Loss/Testing Loss": 0.8621585901681479, "mean_training_loss": 0.016129706505065164}, "Round 33": {"Accuracy/Testing Accuracy": 0.7298701298701299, "Loss/Testing Loss": 0.866429426298513, "mean_training_loss": 0.027034480726191152}, "Round 34": {"Accuracy/Testing Accuracy": 0.7246753246753247, "Loss/Testing Loss": 0.8868528782547295, "mean_training_loss": 0.06803197199013085}, "Round 35": {"Accuracy/Testing Accuracy": 0.7246753246753247, "Loss/Testing Loss": 0.8765137062444315, "mean_training_loss": 0.03659829187206924}, "Round 36": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.8561005178984109, "mean_training_loss": 0.03440688321339515}, "Round 37": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.8771675102122418, "mean_training_loss": 0.08030243484642018}, "Round 38": {"Accuracy/Testing Accuracy": 0.7207792207792207, "Loss/Testing Loss": 0.8815480938205471, "mean_training_loss": 0.021876343155745416}, "Round 39": {"Accuracy/Testing Accuracy": 0.7389610389610389, "Loss/Testing Loss": 0.8613237072895099, "mean_training_loss": 0.03537978062328572}, "Round 40": {"Accuracy/Testing Accuracy": 0.7389610389610389, "Loss/Testing Loss": 0.8378733610177969, "mean_training_loss": 0.1817976305599917}, "Round 41": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.831071104322161, "mean_training_loss": 0.015755398184992372}, "Round 42": {"Accuracy/Testing Accuracy": 0.7441558441558441, "Loss/Testing Loss": 0.8281080160822187, "mean_training_loss": 0.04513115828158334}, "Round 43": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8215824978692191, "mean_training_loss": 0.026539033827268417}, "Round 44": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8141865796857066, "mean_training_loss": 0.011544826402678154}, "Round 45": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8099216832743062, "mean_training_loss": 0.02057449497446856}, "Round 46": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8041438262183945, "mean_training_loss": 0.5796316722821858}, "Round 47": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8201841015320319, "mean_training_loss": 0.007883072060940322}, "Round 48": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8160316156102465, "mean_training_loss": 0.01028583080333192}, "Round 49": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8040493883095778, "mean_training_loss": 0.006358836900132399}, "Round 50": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.7944148466184542, "mean_training_loss": 0.1362274245528335}, "Round 51": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7861740544244841, "mean_training_loss": 0.008765967962715556}, "Round 52": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7727986445674648, "mean_training_loss": 0.008260713256895542}, "Round 53": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7704271302594767, "mean_training_loss": 0.5330207832209353}, "Round 54": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8237799805480165, "mean_training_loss": 0.007830791044721588}, "Round 55": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8023307557229872, "mean_training_loss": 0.025335436477325855}, "Round 56": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.8600278786250524, "mean_training_loss": 0.5877159665513318}, "Round 57": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.8668714992411725, "mean_training_loss": 0.16256544387433677}, "Round 58": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.8766872074696925, "mean_training_loss": 0.016784559877808476}, "Round 59": {"Accuracy/Testing Accuracy": 0.7376623376623377, "Loss/Testing Loss": 0.8432854347414784, "mean_training_loss": 0.008279533177200291}, "Round 60": {"Accuracy/Testing Accuracy": 0.7389610389610389, "Loss/Testing Loss": 0.8253960039708521, "mean_training_loss": 0.0028538181434851137}, "Round 61": {"Accuracy/Testing Accuracy": 0.7298701298701299, "Loss/Testing Loss": 0.8345662940632214, "mean_training_loss": 0.06430718930099497}, "Round 62": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8191177465698936, "mean_training_loss": 0.002991159676457755}, "Round 63": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.8103444395127235, "mean_training_loss": 0.18462091155902102}, "Round 64": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.8557818545923604, "mean_training_loss": 0.020114198299900934}, "Round 65": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8887188906793471, "mean_training_loss": 0.01673536341473022}, "Round 66": {"Accuracy/Testing Accuracy": 0.7389610389610389, "Loss/Testing Loss": 0.9021578044086308, "mean_training_loss": 0.030467083137482403}, "Round 67": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.85519289289202, "mean_training_loss": 0.36195913444140126}, "Round 68": {"Accuracy/Testing Accuracy": 0.7337662337662337, "Loss/Testing Loss": 0.8825581632651291, "mean_training_loss": 0.04421127745059921}, "Round 69": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.8680260088536647, "mean_training_loss": 0.01856942102571742}, "Round 70": {"Accuracy/Testing Accuracy": 0.7298701298701299, "Loss/Testing Loss": 0.9026496970808351, "mean_training_loss": 0.029890260040102635}, "Round 71": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.8588686665931305, "mean_training_loss": 0.025424568717911218}, "Round 72": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.818692266631436, "mean_training_loss": 0.006223126399134727}, "Round 73": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.810350521818384, "mean_training_loss": 0.024184965940366964}, "Round 74": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8096309994722342, "mean_training_loss": 0.0036975781392196523}, "Round 75": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.7967165394262834, "mean_training_loss": 0.0036183391686063263}, "Round 76": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.7893219082386462, "mean_training_loss": 0.011510797139061123}, "Round 77": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.7837031537836249, "mean_training_loss": 0.4020047415580068}, "Round 78": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.800299790308073, "mean_training_loss": 0.007696175984548112}, "Round 79": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.7825472788377241, "mean_training_loss": 0.005102576923213507}, "Round 80": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.777558358149095, "mean_training_loss": 0.007334073077072389}, "Round 81": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.7909364446417078, "mean_training_loss": 0.004592992264875456}, "Round 82": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7807669867168773, "mean_training_loss": 0.007598933051728335}, "Round 83": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7859933108478397, "mean_training_loss": 0.004017103019194971}, "Round 84": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.7844081116961195, "mean_training_loss": 0.00617702073924353}, "Round 85": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.80428431606912, "mean_training_loss": 0.00702195310004754}, "Round 86": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7910118816734908, "mean_training_loss": 0.0074308886464374765}, "Round 87": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7785394026087477, "mean_training_loss": 0.016039446990180294}, "Round 88": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7778631029190956, "mean_training_loss": 0.005438389966117316}, "Round 89": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7694693504989921, "mean_training_loss": 0.004086570509121213}, "Round 90": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.7992605460154546, "mean_training_loss": 0.005504288030351745}, "Round 91": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8281224865417975, "mean_training_loss": 0.0040518438175786275}, "Round 92": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.8525564340801982, "mean_training_loss": 0.006914176104443245}, "Round 93": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8096592714260151, "mean_training_loss": 0.004338707978910718}, "Round 94": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.773996458270333, "mean_training_loss": 0.003935581730329432}, "Round 95": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.79815635417963, "mean_training_loss": 0.00431058293968243}, "Round 96": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.7765979209503571, "mean_training_loss": 0.007240871756221168}, "Round 97": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8307847250591625, "mean_training_loss": 0.007259832792367566}, "Round 98": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8008408964454353, "mean_training_loss": 0.005006013048420612}, "Round 99": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8093045069025708, "mean_training_loss": 0.009507021243916825}, "Round 100": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.7906481256732693, "mean_training_loss": 0.007734954537590965}, "Round 101": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.7996029119986993, "mean_training_loss": 0.0068964486340216055}, "Round 102": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8218849045889718, "mean_training_loss": 0.0076012863195501264}, "Round 103": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8016917564652183, "mean_training_loss": 0.00496725790067821}, "Round 104": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.7965702135841568, "mean_training_loss": 0.012819325030945678}}