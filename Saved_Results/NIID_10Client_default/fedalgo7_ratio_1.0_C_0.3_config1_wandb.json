{"Round 1": {"Accuracy/Testing Accuracy": 0.012987012987012988, "Loss/Testing Loss": 4.517292786883069, "mean_training_loss": 1.4350043890115463}, "Round 2": {"Accuracy/Testing Accuracy": 0.05844155844155844, "Loss/Testing Loss": 4.1255080706113345, "mean_training_loss": 1.098579098172486}, "Round 3": {"Accuracy/Testing Accuracy": 0.17012987012987013, "Loss/Testing Loss": 3.652307877602515, "mean_training_loss": 0.8764217624342757}, "Round 4": {"Accuracy/Testing Accuracy": 0.2701298701298701, "Loss/Testing Loss": 3.126492611154333, "mean_training_loss": 0.7569706996793256}, "Round 5": {"Accuracy/Testing Accuracy": 0.32987012987012987, "Loss/Testing Loss": 2.7395758672194046, "mean_training_loss": 0.5177876113864937}, "Round 6": {"Accuracy/Testing Accuracy": 0.38441558441558443, "Loss/Testing Loss": 2.4195379368670573, "mean_training_loss": 0.5653393533346909}, "Round 7": {"Accuracy/Testing Accuracy": 0.44155844155844154, "Loss/Testing Loss": 2.1216444919635724, "mean_training_loss": 0.3550361729330487}, "Round 8": {"Accuracy/Testing Accuracy": 0.4961038961038961, "Loss/Testing Loss": 1.8603078913379025, "mean_training_loss": 0.32477452004949253}, "Round 9": {"Accuracy/Testing Accuracy": 0.5415584415584416, "Loss/Testing Loss": 1.7056524985796446, "mean_training_loss": 0.47863045698878437}, "Round 10": {"Accuracy/Testing Accuracy": 0.5623376623376624, "Loss/Testing Loss": 1.574973978315081, "mean_training_loss": 0.737988284493194}, "Round 11": {"Accuracy/Testing Accuracy": 0.5974025974025974, "Loss/Testing Loss": 1.4217182636260985, "mean_training_loss": 0.26008466955274345}, "Round 12": {"Accuracy/Testing Accuracy": 0.6116883116883117, "Loss/Testing Loss": 1.3777224974198774, "mean_training_loss": 0.20452201458226357}, "Round 13": {"Accuracy/Testing Accuracy": 0.6415584415584416, "Loss/Testing Loss": 1.3040456855451905, "mean_training_loss": 0.14753191580375039}, "Round 14": {"Accuracy/Testing Accuracy": 0.6480519480519481, "Loss/Testing Loss": 1.2502804650888815, "mean_training_loss": 0.1541203218183535}, "Round 15": {"Accuracy/Testing Accuracy": 0.6584415584415585, "Loss/Testing Loss": 1.200202178335809, "mean_training_loss": 0.39656462324783204}, "Round 16": {"Accuracy/Testing Accuracy": 0.6766233766233766, "Loss/Testing Loss": 1.165134495264524, "mean_training_loss": 0.23351427430615704}, "Round 17": {"Accuracy/Testing Accuracy": 0.6766233766233766, "Loss/Testing Loss": 1.1488297496523177, "mean_training_loss": 0.11484153639175929}, "Round 18": {"Accuracy/Testing Accuracy": 0.6805194805194805, "Loss/Testing Loss": 1.106630325936652, "mean_training_loss": 0.11060232381251726}, "Round 19": {"Accuracy/Testing Accuracy": 0.687012987012987, "Loss/Testing Loss": 1.1049452177889936, "mean_training_loss": 0.034158607983651265}, "Round 20": {"Accuracy/Testing Accuracy": 0.6987012987012987, "Loss/Testing Loss": 1.070170503158074, "mean_training_loss": 0.07428534204539443}, "Round 21": {"Accuracy/Testing Accuracy": 0.7051948051948052, "Loss/Testing Loss": 1.0321768039232724, "mean_training_loss": 0.5962357023358346}, "Round 22": {"Accuracy/Testing Accuracy": 0.7077922077922078, "Loss/Testing Loss": 1.0242794783084423, "mean_training_loss": 0.3477101624689319}, "Round 23": {"Accuracy/Testing Accuracy": 0.7116883116883117, "Loss/Testing Loss": 1.0355331050885188, "mean_training_loss": 0.12359195418345433}, "Round 24": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.9802247242494063, "mean_training_loss": 0.09979768012417481}, "Round 25": {"Accuracy/Testing Accuracy": 0.7181818181818181, "Loss/Testing Loss": 0.9599902303187878, "mean_training_loss": 0.07379221370443702}, "Round 26": {"Accuracy/Testing Accuracy": 0.7038961038961039, "Loss/Testing Loss": 0.9858567496398827, "mean_training_loss": 0.032898181074831105}, "Round 27": {"Accuracy/Testing Accuracy": 0.7181818181818181, "Loss/Testing Loss": 0.9629804586435293, "mean_training_loss": 0.03776033821632154}, "Round 28": {"Accuracy/Testing Accuracy": 0.7337662337662337, "Loss/Testing Loss": 0.9247333004877165, "mean_training_loss": 0.8936442700680345}, "Round 29": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 1.0147165190089833, "mean_training_loss": 0.031217445043980014}, "Round 30": {"Accuracy/Testing Accuracy": 0.6974025974025974, "Loss/Testing Loss": 0.9811358406946257, "mean_training_loss": 0.048423535963520406}, "Round 31": {"Accuracy/Testing Accuracy": 0.7103896103896103, "Loss/Testing Loss": 0.9390818684132068, "mean_training_loss": 0.06848337543620305}, "Round 32": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9133291783270898, "mean_training_loss": 0.022026715910231524}, "Round 33": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.9127662359894096, "mean_training_loss": 0.03629057023596639}, "Round 34": {"Accuracy/Testing Accuracy": 0.7324675324675325, "Loss/Testing Loss": 0.8957200813603091, "mean_training_loss": 0.06495920717716216}, "Round 35": {"Accuracy/Testing Accuracy": 0.7363636363636363, "Loss/Testing Loss": 0.8646358497731097, "mean_training_loss": 0.054978603851050134}, "Round 36": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.8498800674042144, "mean_training_loss": 0.02704136997635942}, "Round 37": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.8281113799516256, "mean_training_loss": 0.029114160938188433}, "Round 38": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.8230054507007847, "mean_training_loss": 0.028138360842131078}, "Round 39": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.817936502339004, "mean_training_loss": 0.68236207261992}, "Round 40": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.823301084629901, "mean_training_loss": 0.027143042520619925}, "Round 41": {"Accuracy/Testing Accuracy": 0.7363636363636363, "Loss/Testing Loss": 0.814007693761355, "mean_training_loss": 0.13521827853877436}, "Round 42": {"Accuracy/Testing Accuracy": 0.7363636363636363, "Loss/Testing Loss": 0.8427639430219477, "mean_training_loss": 0.010595876053692057}, "Round 43": {"Accuracy/Testing Accuracy": 0.7337662337662337, "Loss/Testing Loss": 0.8520938035729644, "mean_training_loss": 0.05438480369953645}, "Round 44": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8275302351295174, "mean_training_loss": 0.01050744393410591}, "Round 45": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8590219070385029, "mean_training_loss": 0.4826281744548503}, "Round 46": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.865845407603623, "mean_training_loss": 0.5472467175958788}, "Round 47": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9426589388351936, "mean_training_loss": 0.044661273385087644}, "Round 48": {"Accuracy/Testing Accuracy": 0.7337662337662337, "Loss/Testing Loss": 0.9160182144734766, "mean_training_loss": 0.009983362413809767}, "Round 49": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.8727265469439618, "mean_training_loss": 0.028305565075327953}, "Round 50": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8488934982906688, "mean_training_loss": 0.02298436262179166}, "Round 51": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8130300930568151, "mean_training_loss": 0.010900654043070971}, "Round 52": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8056362625840422, "mean_training_loss": 0.010658378610387445}, "Round 53": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.80995525338433, "mean_training_loss": 0.580339974630624}, "Round 54": {"Accuracy/Testing Accuracy": 0.7324675324675325, "Loss/Testing Loss": 0.8615224550296734, "mean_training_loss": 0.009246657434029176}, "Round 55": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8181224895762159, "mean_training_loss": 0.02130592492952322}, "Round 56": {"Accuracy/Testing Accuracy": 0.7402597402597403, "Loss/Testing Loss": 0.8533144797597613, "mean_training_loss": 0.003638419181418916}, "Round 57": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8295972136708049, "mean_training_loss": 0.20445614672498777}, "Round 58": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8170381710126803, "mean_training_loss": 0.008302827495807673}, "Round 59": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.8121363288396365, "mean_training_loss": 0.006707714432074378}, "Round 60": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.8301804057963482, "mean_training_loss": 0.004595697526820004}, "Round 61": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8122972539493016, "mean_training_loss": 0.019754193382422354}, "Round 62": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.817833090912212, "mean_training_loss": 0.8265764410793782}, "Round 63": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.9105221847435097, "mean_training_loss": 0.008529054956591647}, "Round 64": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.8637900468590972, "mean_training_loss": 0.021941645957783543}, "Round 65": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.8381547966560761, "mean_training_loss": 0.5391837827744894}, "Round 66": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8261231118982488, "mean_training_loss": 0.029280618820339437}, "Round 67": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.8089824569689763, "mean_training_loss": 0.4777852326755722}, "Round 68": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.840824685932754, "mean_training_loss": 0.08454479792100542}, "Round 69": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8181609020604715, "mean_training_loss": 0.007625681625090933}, "Round 70": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8048072830423132, "mean_training_loss": 0.009923360350213068}, "Round 71": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.7934265084080881, "mean_training_loss": 0.014043630725196137}, "Round 72": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8463347504665325, "mean_training_loss": 0.03259714933422705}, "Round 73": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8193509269070316, "mean_training_loss": 0.02263091739441734}, "Round 74": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8200308648022738, "mean_training_loss": 0.003920874906950356}, "Round 75": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7974428607271863, "mean_training_loss": 0.003232886828482151}, "Round 76": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.784074354171753, "mean_training_loss": 0.007511283437672413}, "Round 77": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.781214472690186, "mean_training_loss": 0.2603322665340134}, "Round 78": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7890720138302098, "mean_training_loss": 0.006558156137256637}, "Round 79": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7824889141243774, "mean_training_loss": 0.3189807342091465}, "Round 80": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8305857808558972, "mean_training_loss": 0.007475583672203356}, "Round 81": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.8285640770738775, "mean_training_loss": 0.0051920023796680785}, "Round 82": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8138799927451393, "mean_training_loss": 0.008616490546652738}, "Round 83": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8159910137003118, "mean_training_loss": 0.0030140367508130635}, "Round 84": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.818108027476769, "mean_training_loss": 0.007540408798548229}, "Round 85": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8410710704791081, "mean_training_loss": 0.007712824049667688}, "Round 86": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8135116874397575, "mean_training_loss": 0.009450028421865268}, "Round 87": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8175789215347984, "mean_training_loss": 0.005322497154702432}, "Round 88": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8052943369010827, "mean_training_loss": 0.006628805596234374}, "Round 89": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7987305192204265, "mean_training_loss": 0.0049734045119423954}, "Round 90": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.7876581893338785, "mean_training_loss": 0.004532954590104055}, "Round 91": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8082475908390887, "mean_training_loss": 0.003672647073981352}, "Round 92": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8362851884457972, "mean_training_loss": 0.005542797287926077}, "Round 93": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8110895785418424, "mean_training_loss": 0.003876364831567595}, "Round 94": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.791983259498299, "mean_training_loss": 0.0037995224719634276}, "Round 95": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.8378521711795361, "mean_training_loss": 0.0038102382309979908}, "Round 96": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8134823119485534, "mean_training_loss": 0.01147302366734948}, "Round 97": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.858220044204167, "mean_training_loss": 0.005496750684345469}, "Round 98": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8274302259668127, "mean_training_loss": 0.003843996686076647}, "Round 99": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.8347477962444355, "mean_training_loss": 0.010739025597771009}, "Round 100": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.815879416310942, "mean_training_loss": 0.008890475744071107}, "Round 101": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8093668688427318, "mean_training_loss": 0.006605274620233104}, "Round 102": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8460280105665132, "mean_training_loss": 0.00895275105528223}, "Round 103": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8259252421267621, "mean_training_loss": 0.003705341112799943}, "Round 104": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.817728083164661, "mean_training_loss": 0.0079434159622692}, "Round 105": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8038407167831024, "mean_training_loss": 0.0033900522712716147}, "Round 106": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.8013450995668189, "mean_training_loss": 0.006627911077036211}, "Round 107": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7915713821138655, "mean_training_loss": 0.001824969176474648}, "Round 108": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.7879572029237624, "mean_training_loss": 0.020635289902566002}, "Round 109": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.7884724313562567, "mean_training_loss": 0.002698893457847206}, "Round 110": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.7928794746275072, "mean_training_loss": 0.005074180641289179}, "Round 111": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7904436481463445, "mean_training_loss": 0.002999624022392227}, "Round 112": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.829937930540605, "mean_training_loss": 0.0029045149880020243}, "Round 113": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8184235874708596, "mean_training_loss": 0.004172206077491864}, "Round 114": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.8482684483775845, "mean_training_loss": 0.0030862295761165262}, "Round 115": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8281444647095421, "mean_training_loss": 0.005795628181658685}, "Round 116": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8185081198618009, "mean_training_loss": 0.006400286524634188}, "Round 117": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.8103100220878403, "mean_training_loss": 0.006278651911998168}, "Round 118": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.8073247873937929, "mean_training_loss": 0.002248564231558703}, "Round 119": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.797230205288181, "mean_training_loss": 0.0028659487355445676}, "Round 120": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.8219408645258321, "mean_training_loss": 0.003134030687129673}, "Round 121": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8095596934293772, "mean_training_loss": 0.0034313142777567633}, "Round 122": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7945616352093684, "mean_training_loss": 0.0029545161965009023}, "Round 123": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7893217963057679, "mean_training_loss": 0.0019315849046688525}, "Round 124": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8324943396952245, "mean_training_loss": 0.003207902893375017}, "Round 125": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.820487114206537, "mean_training_loss": 0.00886083638955218}, "Round 126": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.811237206087484, "mean_training_loss": 0.007794179732445628}, "Round 127": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.8075257959303918, "mean_training_loss": 0.003195548771182076}}