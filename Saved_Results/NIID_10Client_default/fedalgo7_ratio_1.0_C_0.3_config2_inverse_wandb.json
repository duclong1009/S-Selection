{"Round 1": {"Accuracy/Testing Accuracy": 0.012987012987012988, "Loss/Testing Loss": 4.517292786883069, "mean_training_loss": 1.4350043890115463}, "Round 2": {"Accuracy/Testing Accuracy": 0.05844155844155844, "Loss/Testing Loss": 4.1255080706113345, "mean_training_loss": 1.098579098172486}, "Round 3": {"Accuracy/Testing Accuracy": 0.17012987012987013, "Loss/Testing Loss": 3.652307877602515, "mean_training_loss": 0.8764217624342757}, "Round 4": {"Accuracy/Testing Accuracy": 0.2701298701298701, "Loss/Testing Loss": 3.126492611154333, "mean_training_loss": 0.7569706996793256}, "Round 5": {"Accuracy/Testing Accuracy": 0.32987012987012987, "Loss/Testing Loss": 2.7395758672194046, "mean_training_loss": 0.5177876113864937}, "Round 6": {"Accuracy/Testing Accuracy": 0.38441558441558443, "Loss/Testing Loss": 2.4195379368670573, "mean_training_loss": 0.5607921555638314}, "Round 7": {"Accuracy/Testing Accuracy": 0.43246753246753245, "Loss/Testing Loss": 2.1402239842848343, "mean_training_loss": 0.4894133532748504}, "Round 8": {"Accuracy/Testing Accuracy": 0.4935064935064935, "Loss/Testing Loss": 1.9247463446158868, "mean_training_loss": 0.4371988257659333}, "Round 9": {"Accuracy/Testing Accuracy": 0.538961038961039, "Loss/Testing Loss": 1.7739814154513471, "mean_training_loss": 1.0485091004859317}, "Round 10": {"Accuracy/Testing Accuracy": 0.5584415584415584, "Loss/Testing Loss": 1.625335776341426, "mean_training_loss": 0.3259521359453599}, "Round 11": {"Accuracy/Testing Accuracy": 0.5922077922077922, "Loss/Testing Loss": 1.5042318313152758, "mean_training_loss": 0.272476106757919}, "Round 12": {"Accuracy/Testing Accuracy": 0.6116883116883117, "Loss/Testing Loss": 1.4267718299642786, "mean_training_loss": 0.2429398069301477}, "Round 13": {"Accuracy/Testing Accuracy": 0.6324675324675325, "Loss/Testing Loss": 1.3224685653463586, "mean_training_loss": 0.21647085872744873}, "Round 14": {"Accuracy/Testing Accuracy": 0.638961038961039, "Loss/Testing Loss": 1.2610376333261466, "mean_training_loss": 0.1963045696960762}, "Round 15": {"Accuracy/Testing Accuracy": 0.6675324675324675, "Loss/Testing Loss": 1.2204805730225203, "mean_training_loss": 0.20165875814008438}, "Round 16": {"Accuracy/Testing Accuracy": 0.6831168831168831, "Loss/Testing Loss": 1.1695764646901712, "mean_training_loss": 0.10859513542998364}, "Round 17": {"Accuracy/Testing Accuracy": 0.6896103896103896, "Loss/Testing Loss": 1.1630825076784406, "mean_training_loss": 0.14930104493327873}, "Round 18": {"Accuracy/Testing Accuracy": 0.6818181818181818, "Loss/Testing Loss": 1.1138579117787348, "mean_training_loss": 0.21183736842746534}, "Round 19": {"Accuracy/Testing Accuracy": 0.6987012987012987, "Loss/Testing Loss": 1.0931000025241406, "mean_training_loss": 0.1838965453580022}, "Round 20": {"Accuracy/Testing Accuracy": 0.6935064935064935, "Loss/Testing Loss": 1.0867951681087544, "mean_training_loss": 0.06753247095205422}, "Round 21": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 1.0519817024082332, "mean_training_loss": 0.0636408108472824}, "Round 22": {"Accuracy/Testing Accuracy": 0.687012987012987, "Loss/Testing Loss": 1.0412956813713172, "mean_training_loss": 0.11424723877994851}, "Round 23": {"Accuracy/Testing Accuracy": 0.6974025974025974, "Loss/Testing Loss": 1.0154413704748277, "mean_training_loss": 0.09856534726503821}, "Round 24": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9588827959902875, "mean_training_loss": 0.12585950428072143}, "Round 25": {"Accuracy/Testing Accuracy": 0.7181818181818181, "Loss/Testing Loss": 0.9415477938466258, "mean_training_loss": 0.19486712322316385}, "Round 26": {"Accuracy/Testing Accuracy": 0.7142857142857143, "Loss/Testing Loss": 0.9290445711705592, "mean_training_loss": 0.03392820347721378}, "Round 27": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.9152112262589591, "mean_training_loss": 0.03379239705391228}, "Round 28": {"Accuracy/Testing Accuracy": 0.7324675324675325, "Loss/Testing Loss": 0.8918730902981449, "mean_training_loss": 0.02929568766780636}, "Round 29": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.9069648957871771, "mean_training_loss": 0.6171492157628139}, "Round 30": {"Accuracy/Testing Accuracy": 0.7246753246753247, "Loss/Testing Loss": 0.9303399404922089, "mean_training_loss": 0.05091455124202184}, "Round 31": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.8937537532348138, "mean_training_loss": 0.07443171176974747}, "Round 32": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.8975660129026933, "mean_training_loss": 0.021430744823068382}, "Round 33": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.878783966968586, "mean_training_loss": 0.034573129729296145}, "Round 34": {"Accuracy/Testing Accuracy": 0.7402597402597403, "Loss/Testing Loss": 0.851073965468964, "mean_training_loss": 0.054529094644822175}, "Round 35": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.842495006245452, "mean_training_loss": 0.2768813323906877}, "Round 36": {"Accuracy/Testing Accuracy": 0.7415584415584415, "Loss/Testing Loss": 0.8569549283423981, "mean_training_loss": 0.048021228774450725}, "Round 37": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8452599194142726, "mean_training_loss": 0.03290690768256106}, "Round 38": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8319627613216252, "mean_training_loss": 0.01992491308134049}, "Round 39": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8254241739000593, "mean_training_loss": 0.05287825606452923}, "Round 40": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.8119089403709808, "mean_training_loss": 0.18586123815991662}, "Round 41": {"Accuracy/Testing Accuracy": 0.7298701298701299, "Loss/Testing Loss": 0.8995730604444231, "mean_training_loss": 0.025873753923753445}, "Round 42": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.85655984259271, "mean_training_loss": 0.01626958489107589}, "Round 43": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8317336650637838, "mean_training_loss": 0.025560864376732044}, "Round 44": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.810399388183247, "mean_training_loss": 0.012540978891775013}, "Round 45": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8006847172588497, "mean_training_loss": 0.09166887052253717}, "Round 46": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7871244069817779, "mean_training_loss": 0.022073511105392955}, "Round 47": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7841863031511183, "mean_training_loss": 0.012393660023291078}, "Round 48": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7962547910677922, "mean_training_loss": 0.009225854532354895}, "Round 49": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7873888169016157, "mean_training_loss": 0.01454332428984344}, "Round 50": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7771364948966286, "mean_training_loss": 0.6814924281090498}, "Round 51": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.7860138210383328, "mean_training_loss": 0.009657200555974507}, "Round 52": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7730448112859354, "mean_training_loss": 0.009266113474344216}, "Round 53": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7701497677084688, "mean_training_loss": 0.007122055619188092}, "Round 54": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8112934045977407, "mean_training_loss": 0.02319269102687637}, "Round 55": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.8374931268877798, "mean_training_loss": 0.16476653716103598}, "Round 56": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8232331610345222, "mean_training_loss": 0.006417812638621972}, "Round 57": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.816158419305628, "mean_training_loss": 0.09403373739992579}, "Round 58": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8347843580431752, "mean_training_loss": 0.016976993211152914}, "Round 59": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8099304584713726, "mean_training_loss": 0.4895099521271492}, "Round 60": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.8590695820845566, "mean_training_loss": 0.007270448203933866}, "Round 61": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8347467837395606, "mean_training_loss": 0.01741925685433671}, "Round 62": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8198050780729814, "mean_training_loss": 0.09959466147579646}, "Round 63": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8049833443257716, "mean_training_loss": 0.006539046866819264}, "Round 64": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.7860445723905192, "mean_training_loss": 0.014289461632936516}, "Round 65": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8228427292464615, "mean_training_loss": 0.01225651088025188}, "Round 66": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.8249718895206204, "mean_training_loss": 0.11132145246956497}, "Round 67": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.8089773117721855, "mean_training_loss": 0.014494598146456364}, "Round 68": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.789270981875333, "mean_training_loss": 0.014512097233091482}, "Round 69": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7710919129384028, "mean_training_loss": 0.0073304561090052995}, "Round 70": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7655351274973387, "mean_training_loss": 0.011204039258882404}, "Round 71": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7514997637117063, "mean_training_loss": 0.011982518991377825}, "Round 72": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7489307343185722, "mean_training_loss": 0.005177362329947452}, "Round 73": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7512913827772264, "mean_training_loss": 0.022655678531737066}, "Round 74": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.762922778222468, "mean_training_loss": 0.003777027131496545}, "Round 75": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7516898351830321, "mean_training_loss": 0.005357692818506621}, "Round 76": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.740631708077022, "mean_training_loss": 0.007468254900978584}, "Round 77": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.744910466051721, "mean_training_loss": 0.008888869549679969}, "Round 78": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7623973007326003, "mean_training_loss": 0.004818984802420202}, "Round 79": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7586631401792749, "mean_training_loss": 0.004185365712098581}, "Round 80": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7545062306639436, "mean_training_loss": 0.010019212153565604}, "Round 81": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7565174252955944, "mean_training_loss": 0.0037546471386265593}, "Round 82": {"Accuracy/Testing Accuracy": 0.7779220779220779, "Loss/Testing Loss": 0.7542125376788053, "mean_training_loss": 0.006074487851583399}, "Round 83": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.7606138845542809, "mean_training_loss": 0.17084158792276866}, "Round 84": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7973614090448851, "mean_training_loss": 0.006392000559443499}, "Round 85": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.8076438631330217, "mean_training_loss": 0.021906575368484484}, "Round 86": {"Accuracy/Testing Accuracy": 0.7740259740259741, "Loss/Testing Loss": 0.7834305487669908, "mean_training_loss": 0.012598389643244445}, "Round 87": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.7903005779563607, "mean_training_loss": 0.007512075822160113}, "Round 88": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7801473516922492, "mean_training_loss": 0.004222948762196067}, "Round 89": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7747089053129221, "mean_training_loss": 0.003257917935690402}, "Round 90": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.779499329220165, "mean_training_loss": 0.0044748316198820245}, "Round 91": {"Accuracy/Testing Accuracy": 0.7740259740259741, "Loss/Testing Loss": 0.8134390121930606, "mean_training_loss": 0.006886594054521992}, "Round 92": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.8654871553569645, "mean_training_loss": 0.005009256537366462}, "Round 93": {"Accuracy/Testing Accuracy": 0.7597402597402597, "Loss/Testing Loss": 0.8243786765383435, "mean_training_loss": 0.0040749263667844635}, "Round 94": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.8057318368515411, "mean_training_loss": 0.026598753440193836}, "Round 95": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.8480186049040261, "mean_training_loss": 0.004237280772557776}, "Round 96": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.8221243791765981, "mean_training_loss": 0.019783238563104533}, "Round 97": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8661817064532986, "mean_training_loss": 0.12015722995856777}, "Round 98": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.8435406156948635, "mean_training_loss": 0.005223033468753688}, "Round 99": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8273227730354705, "mean_training_loss": 0.011135761953967935}, "Round 100": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.8119887508355178, "mean_training_loss": 0.008684560425657158}, "Round 101": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.8025432814251293, "mean_training_loss": 0.006305929665298511}, "Round 102": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.8474746846533441, "mean_training_loss": 0.008598845064019162}, "Round 103": {"Accuracy/Testing Accuracy": 0.7740259740259741, "Loss/Testing Loss": 0.8218631834178776, "mean_training_loss": 0.0036930555447102767}, "Round 104": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.8086189270019531, "mean_training_loss": 0.009019769992515006}, "Round 105": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7890913602593658, "mean_training_loss": 0.0032296767397048446}, "Round 106": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.7826503222638911, "mean_training_loss": 0.006033457538190608}, "Round 107": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7815759469936421, "mean_training_loss": 0.002056860888648468}, "Round 108": {"Accuracy/Testing Accuracy": 0.7792207792207793, "Loss/Testing Loss": 0.771507258539076, "mean_training_loss": 0.006502499549242202}, "Round 109": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7637474490450574, "mean_training_loss": 0.003018668952005866}, "Round 110": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.757067727732968, "mean_training_loss": 0.0048703088308684524}, "Round 111": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7553494207270733, "mean_training_loss": 0.0033225672538666163}, "Round 112": {"Accuracy/Testing Accuracy": 0.7831168831168831, "Loss/Testing Loss": 0.7930607303396447, "mean_training_loss": 0.002976071159355342}, "Round 113": {"Accuracy/Testing Accuracy": 0.7779220779220779, "Loss/Testing Loss": 0.7764471464342885, "mean_training_loss": 0.00434293998638168}, "Round 114": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.8075868631338144, "mean_training_loss": 0.0032404046683376167}, "Round 115": {"Accuracy/Testing Accuracy": 0.7792207792207793, "Loss/Testing Loss": 0.7934635137582754, "mean_training_loss": 0.006138646510225954}, "Round 116": {"Accuracy/Testing Accuracy": 0.7779220779220779, "Loss/Testing Loss": 0.7888284054669467, "mean_training_loss": 0.005554477418384825}, "Round 117": {"Accuracy/Testing Accuracy": 0.787012987012987, "Loss/Testing Loss": 0.7827462425479641, "mean_training_loss": 0.005634728696895764}, "Round 118": {"Accuracy/Testing Accuracy": 0.7831168831168831, "Loss/Testing Loss": 0.7806096632759293, "mean_training_loss": 0.002533607706427574}, "Round 119": {"Accuracy/Testing Accuracy": 0.7818181818181819, "Loss/Testing Loss": 0.7722036499481697, "mean_training_loss": 0.002847104350461022}, "Round 120": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7965016075542994, "mean_training_loss": 0.0033263974254676963}, "Round 121": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7819364470320863, "mean_training_loss": 0.0029965444143224317}, "Round 122": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7770556330680847, "mean_training_loss": 0.0031294863095114893}}