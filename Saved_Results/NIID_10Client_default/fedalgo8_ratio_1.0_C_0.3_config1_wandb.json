{"Round 1": {"Accuracy/Testing Accuracy": 0.012987012987012988, "Loss/Testing Loss": 4.517292786883069, "mean_training_loss": 1.4350043890115463}, "Round 2": {"Accuracy/Testing Accuracy": 0.05844155844155844, "Loss/Testing Loss": 4.1255080706113345, "mean_training_loss": 1.098579098172486}, "Round 3": {"Accuracy/Testing Accuracy": 0.17012987012987013, "Loss/Testing Loss": 3.652307877602515, "mean_training_loss": 0.8764217624342757}, "Round 4": {"Accuracy/Testing Accuracy": 0.2701298701298701, "Loss/Testing Loss": 3.126492611154333, "mean_training_loss": 0.7569706996793256}, "Round 5": {"Accuracy/Testing Accuracy": 0.32987012987012987, "Loss/Testing Loss": 2.7395758672194046, "mean_training_loss": 0.5177876113864937}, "Round 6": {"Accuracy/Testing Accuracy": 0.38441558441558443, "Loss/Testing Loss": 2.4195379368670573, "mean_training_loss": 0.5653393533346909}, "Round 7": {"Accuracy/Testing Accuracy": 0.44415584415584414, "Loss/Testing Loss": 2.099030950471952, "mean_training_loss": 0.34050255763447945}, "Round 8": {"Accuracy/Testing Accuracy": 0.5116883116883116, "Loss/Testing Loss": 1.815302646314943, "mean_training_loss": 0.5399454285452763}, "Round 9": {"Accuracy/Testing Accuracy": 0.5363636363636364, "Loss/Testing Loss": 1.6806792095110015, "mean_training_loss": 0.45280605349689723}, "Round 10": {"Accuracy/Testing Accuracy": 0.5623376623376624, "Loss/Testing Loss": 1.5534572310261912, "mean_training_loss": 0.4483141962219688}, "Round 11": {"Accuracy/Testing Accuracy": 0.5818181818181818, "Loss/Testing Loss": 1.4582036262982851, "mean_training_loss": 0.22573829561471942}, "Round 12": {"Accuracy/Testing Accuracy": 0.6194805194805195, "Loss/Testing Loss": 1.363227569902098, "mean_training_loss": 0.1485226411229143}, "Round 13": {"Accuracy/Testing Accuracy": 0.638961038961039, "Loss/Testing Loss": 1.2678311669981326, "mean_training_loss": 0.14021304628501335}, "Round 14": {"Accuracy/Testing Accuracy": 0.6584415584415585, "Loss/Testing Loss": 1.2069504428219486, "mean_training_loss": 0.15216892530922504}, "Round 15": {"Accuracy/Testing Accuracy": 0.6818181818181818, "Loss/Testing Loss": 1.1616106965325095, "mean_training_loss": 0.31256265497455993}, "Round 16": {"Accuracy/Testing Accuracy": 0.687012987012987, "Loss/Testing Loss": 1.1188339573996409, "mean_training_loss": 0.1373364864355501}, "Round 17": {"Accuracy/Testing Accuracy": 0.7038961038961039, "Loss/Testing Loss": 1.102044263133755, "mean_training_loss": 0.2367154913351816}, "Round 18": {"Accuracy/Testing Accuracy": 0.6844155844155844, "Loss/Testing Loss": 1.1583406810636645, "mean_training_loss": 0.12099807029590011}, "Round 19": {"Accuracy/Testing Accuracy": 0.6597402597402597, "Loss/Testing Loss": 1.1729030045596036, "mean_training_loss": 0.019124044274741955}, "Round 20": {"Accuracy/Testing Accuracy": 0.6805194805194805, "Loss/Testing Loss": 1.0995574886148627, "mean_training_loss": 0.09552466608583929}, "Round 21": {"Accuracy/Testing Accuracy": 0.7051948051948052, "Loss/Testing Loss": 1.0341111331791073, "mean_training_loss": 0.05367625388006368}, "Round 22": {"Accuracy/Testing Accuracy": 0.7012987012987013, "Loss/Testing Loss": 1.0403372030753595, "mean_training_loss": 0.09276975505985319}, "Round 23": {"Accuracy/Testing Accuracy": 0.7077922077922078, "Loss/Testing Loss": 0.9966305166095882, "mean_training_loss": 0.093723105900507}, "Round 24": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9495568965936636, "mean_training_loss": 0.05089934372226708}, "Round 25": {"Accuracy/Testing Accuracy": 0.7363636363636363, "Loss/Testing Loss": 0.9027661295680257, "mean_training_loss": 0.8676694226535883}, "Round 26": {"Accuracy/Testing Accuracy": 0.7077922077922078, "Loss/Testing Loss": 0.9853231196279649, "mean_training_loss": 0.04298683570697904}, "Round 27": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9436927160659394, "mean_training_loss": 0.04811510675936006}, "Round 28": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.8929513389414007, "mean_training_loss": 0.03074203569661168}, "Round 29": {"Accuracy/Testing Accuracy": 0.7376623376623377, "Loss/Testing Loss": 0.8727174887409458, "mean_training_loss": 0.023187831708540517}, "Round 30": {"Accuracy/Testing Accuracy": 0.7454545454545455, "Loss/Testing Loss": 0.861164037438182, "mean_training_loss": 0.05011854441836476}, "Round 31": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8414763452170732, "mean_training_loss": 0.05760314238935031}, "Round 32": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8322818768488897, "mean_training_loss": 0.2615477123467082}, "Round 33": {"Accuracy/Testing Accuracy": 0.7441558441558441, "Loss/Testing Loss": 0.911812138557434, "mean_training_loss": 0.03908738431266763}, "Round 34": {"Accuracy/Testing Accuracy": 0.7441558441558441, "Loss/Testing Loss": 0.8624488562732547, "mean_training_loss": 0.05820819883141667}, "Round 35": {"Accuracy/Testing Accuracy": 0.7506493506493507, "Loss/Testing Loss": 0.8499318513003262, "mean_training_loss": 0.036850975474549665}, "Round 36": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8278361331332814, "mean_training_loss": 0.035506793125258646}, "Round 37": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8049018461982925, "mean_training_loss": 0.6451631043106317}, "Round 38": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.7981812408992223, "mean_training_loss": 0.015570101431674426}, "Round 39": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7901148744991847, "mean_training_loss": 0.6036094583881397}, "Round 40": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8286481279831428, "mean_training_loss": 0.016542545580305157}, "Round 41": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8163385917614032, "mean_training_loss": 0.6715851862322201}, "Round 42": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.8565675902676273, "mean_training_loss": 0.01659774495222207}, "Round 43": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8199919505552812, "mean_training_loss": 0.029296912611736094}, "Round 44": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.803495990610742, "mean_training_loss": 0.016905759045039305}, "Round 45": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7872526393308268, "mean_training_loss": 0.013271812196163569}, "Round 46": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7690688142528782, "mean_training_loss": 0.017679540425374667}, "Round 47": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7787846213811404, "mean_training_loss": 0.027781753309278023}, "Round 48": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7818331585301981, "mean_training_loss": 0.040096129263367725}, "Round 49": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.789436175916102, "mean_training_loss": 0.007562751922135552}, "Round 50": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.7793993428155973, "mean_training_loss": 0.013278646916151046}, "Round 51": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.7589871900422233, "mean_training_loss": 0.008730643070302902}, "Round 52": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7498310315144526, "mean_training_loss": 0.007935125562362373}, "Round 53": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.7485547014645167, "mean_training_loss": 0.006794559561240021}, "Round 54": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7462840786227932, "mean_training_loss": 0.0067743353286965026}, "Round 55": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7456891629603002, "mean_training_loss": 0.009618166652084752}, "Round 56": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7474738443052614, "mean_training_loss": 0.021676491720503878}, "Round 57": {"Accuracy/Testing Accuracy": 0.7519480519480519, "Loss/Testing Loss": 0.759587199502177, "mean_training_loss": 0.02719944762997329}, "Round 58": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.7767377755858681, "mean_training_loss": 0.578883870740078}, "Round 59": {"Accuracy/Testing Accuracy": 0.7558441558441559, "Loss/Testing Loss": 0.8524818137094572, "mean_training_loss": 0.004722820707645856}, "Round 60": {"Accuracy/Testing Accuracy": 0.7623376623376623, "Loss/Testing Loss": 0.8306996066848953, "mean_training_loss": 0.005884550925453796}, "Round 61": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8289491041914209, "mean_training_loss": 0.016351536940783264}, "Round 62": {"Accuracy/Testing Accuracy": 0.7467532467532467, "Loss/Testing Loss": 0.8607073983588776, "mean_training_loss": 0.45952844145293864}, "Round 63": {"Accuracy/Testing Accuracy": 0.7376623376623377, "Loss/Testing Loss": 0.899408867606869, "mean_training_loss": 0.029246726802185825}, "Round 64": {"Accuracy/Testing Accuracy": 0.7428571428571429, "Loss/Testing Loss": 0.8803578612092253, "mean_training_loss": 0.01864267708345627}, "Round 65": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8889681904346912, "mean_training_loss": 0.014105650949675369}, "Round 66": {"Accuracy/Testing Accuracy": 0.7350649350649351, "Loss/Testing Loss": 0.9368035539404138, "mean_training_loss": 0.044867813338836035}, "Round 67": {"Accuracy/Testing Accuracy": 0.7480519480519481, "Loss/Testing Loss": 0.8931572589007291, "mean_training_loss": 0.013663511377615997}, "Round 68": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8498754227316224, "mean_training_loss": 0.6481487530776684}, "Round 69": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8394393434772244, "mean_training_loss": 0.009586988019702189}, "Round 70": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8135493484410372, "mean_training_loss": 0.1359141045359566}, "Round 71": {"Accuracy/Testing Accuracy": 0.7532467532467533, "Loss/Testing Loss": 0.8226196024324987, "mean_training_loss": 0.02012968511747507}, "Round 72": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.806267985585448, "mean_training_loss": 0.008650148883461951}, "Round 73": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.806136996869917, "mean_training_loss": 0.02652965295710601}, "Round 74": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.7986790319541832, "mean_training_loss": 0.002831961474080077}, "Round 75": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7856098744776342, "mean_training_loss": 0.003560673623578623}, "Round 76": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7761965313515106, "mean_training_loss": 0.008190873318572382}, "Round 77": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.7744742405879033, "mean_training_loss": 0.0255569854285568}, "Round 78": {"Accuracy/Testing Accuracy": 0.7571428571428571, "Loss/Testing Loss": 0.7870679818190538, "mean_training_loss": 0.016482683061622084}, "Round 79": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7782780377895802, "mean_training_loss": 0.004438309673538529}, "Round 80": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7743850875210453, "mean_training_loss": 0.04490741873160005}, "Round 81": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7885114649673561, "mean_training_loss": 0.0039633538402420905}, "Round 82": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.7771481099066796, "mean_training_loss": 0.00662084589227258}, "Round 83": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7791837207682721, "mean_training_loss": 0.005144524831945697}, "Round 84": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.7809782813121746, "mean_training_loss": 0.004427426640519544}, "Round 85": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.8201026083587052, "mean_training_loss": 0.0076077391429862475}, "Round 86": {"Accuracy/Testing Accuracy": 0.7675324675324675, "Loss/Testing Loss": 0.8017779628951828, "mean_training_loss": 0.00733326724730432}, "Round 87": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7813089516255762, "mean_training_loss": 0.00756137852295069}, "Round 88": {"Accuracy/Testing Accuracy": 0.7636363636363637, "Loss/Testing Loss": 0.7785906927926199, "mean_training_loss": 0.0036993308470731506}, "Round 89": {"Accuracy/Testing Accuracy": 0.7610389610389611, "Loss/Testing Loss": 0.7764570957654482, "mean_training_loss": 0.003221064904018452}, "Round 90": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7961945925440107, "mean_training_loss": 0.008502677651995328}, "Round 91": {"Accuracy/Testing Accuracy": 0.7584415584415585, "Loss/Testing Loss": 0.8246275632412403, "mean_training_loss": 0.004442955283448099}, "Round 92": {"Accuracy/Testing Accuracy": 0.7493506493506493, "Loss/Testing Loss": 0.8586505854284608, "mean_training_loss": 0.008680983283556997}, "Round 93": {"Accuracy/Testing Accuracy": 0.7545454545454545, "Loss/Testing Loss": 0.8185523239049044, "mean_training_loss": 0.003984307070679373}, "Round 94": {"Accuracy/Testing Accuracy": 0.7649350649350649, "Loss/Testing Loss": 0.7998062093536575, "mean_training_loss": 0.0044433684454998}, "Round 95": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.811023739560858, "mean_training_loss": 0.004578721474267934}, "Round 96": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7901144667105241, "mean_training_loss": 0.014813158015022055}, "Round 97": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.8080942732947213, "mean_training_loss": 0.005586610176353989}, "Round 98": {"Accuracy/Testing Accuracy": 0.7727272727272727, "Loss/Testing Loss": 0.7885537514438877, "mean_training_loss": 0.0037541338389641362}, "Round 99": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7748142948398342, "mean_training_loss": 0.007206848389857139}, "Round 100": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.768841294034735, "mean_training_loss": 0.007684788653083767}, "Round 101": {"Accuracy/Testing Accuracy": 0.7779220779220779, "Loss/Testing Loss": 0.7738624490700758, "mean_training_loss": 0.007133413628131772}, "Round 102": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8069358827231766, "mean_training_loss": 0.007029298491155109}, "Round 103": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7935232405538682, "mean_training_loss": 0.003520035214330021}, "Round 104": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7873405267665913, "mean_training_loss": 0.00986351836746668}, "Round 105": {"Accuracy/Testing Accuracy": 0.7701298701298701, "Loss/Testing Loss": 0.7770281077979447, "mean_training_loss": 0.003101271147668166}, "Round 106": {"Accuracy/Testing Accuracy": 0.7766233766233767, "Loss/Testing Loss": 0.7738526189482057, "mean_training_loss": 0.005440976006987815}, "Round 107": {"Accuracy/Testing Accuracy": 0.7688311688311689, "Loss/Testing Loss": 0.7714261742381306, "mean_training_loss": 0.0015794482569132622}, "Round 108": {"Accuracy/Testing Accuracy": 0.7753246753246753, "Loss/Testing Loss": 0.7666040352412633, "mean_training_loss": 0.010891274319874356}, "Round 109": {"Accuracy/Testing Accuracy": 0.7714285714285715, "Loss/Testing Loss": 0.7610342313716938, "mean_training_loss": 0.002713732691604252}, "Round 110": {"Accuracy/Testing Accuracy": 0.7740259740259741, "Loss/Testing Loss": 0.7596589718546186, "mean_training_loss": 0.004479172402837624}, "Round 111": {"Accuracy/Testing Accuracy": 0.7779220779220779, "Loss/Testing Loss": 0.7597813078335354, "mean_training_loss": 0.002810832950533094}, "Round 112": {"Accuracy/Testing Accuracy": 0.7662337662337663, "Loss/Testing Loss": 0.8003499908880753, "mean_training_loss": 0.0027431546826846903}}