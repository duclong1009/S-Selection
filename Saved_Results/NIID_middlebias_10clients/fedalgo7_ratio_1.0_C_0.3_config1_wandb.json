{"Round 1": {"Accuracy/Testing Accuracy": 0.012987012987012988, "Loss/Testing Loss": 4.517292786883069, "mean_training_loss": 0.7095685911178589}, "Round 2": {"Accuracy/Testing Accuracy": 0.023376623376623377, "Loss/Testing Loss": 4.479198027276373, "mean_training_loss": 0.7250282206064598}, "Round 3": {"Accuracy/Testing Accuracy": 0.046753246753246755, "Loss/Testing Loss": 4.35637494372083, "mean_training_loss": 0.6658912032842637}, "Round 4": {"Accuracy/Testing Accuracy": 0.08441558441558442, "Loss/Testing Loss": 4.197139406823493, "mean_training_loss": 0.647232997544894}, "Round 5": {"Accuracy/Testing Accuracy": 0.11428571428571428, "Loss/Testing Loss": 3.9499819396378157, "mean_training_loss": 0.43333019034316145}, "Round 6": {"Accuracy/Testing Accuracy": 0.14415584415584415, "Loss/Testing Loss": 3.874910342228877, "mean_training_loss": 0.5390094718895851}, "Round 7": {"Accuracy/Testing Accuracy": 0.21298701298701297, "Loss/Testing Loss": 3.4822036470685687, "mean_training_loss": 0.4484980485269001}, "Round 8": {"Accuracy/Testing Accuracy": 0.1987012987012987, "Loss/Testing Loss": 3.32896295894276, "mean_training_loss": 0.34759543861210757}, "Round 9": {"Accuracy/Testing Accuracy": 0.261038961038961, "Loss/Testing Loss": 3.1116711517433067, "mean_training_loss": 0.4780021709762514}, "Round 10": {"Accuracy/Testing Accuracy": 0.3012987012987013, "Loss/Testing Loss": 2.9150923103481143, "mean_training_loss": 0.2644327000858119}, "Round 11": {"Accuracy/Testing Accuracy": 0.38181818181818183, "Loss/Testing Loss": 2.5916455349364838, "mean_training_loss": 0.21928581421335158}, "Round 12": {"Accuracy/Testing Accuracy": 0.4090909090909091, "Loss/Testing Loss": 2.424076896518856, "mean_training_loss": 0.18623002098380206}, "Round 13": {"Accuracy/Testing Accuracy": 0.43376623376623374, "Loss/Testing Loss": 2.2910711412305957, "mean_training_loss": 0.14281577886082233}, "Round 14": {"Accuracy/Testing Accuracy": 0.42207792207792205, "Loss/Testing Loss": 2.2680937729872666, "mean_training_loss": 0.18268871643979637}, "Round 15": {"Accuracy/Testing Accuracy": 0.412987012987013, "Loss/Testing Loss": 2.282534020906919, "mean_training_loss": 0.2377946670353413}, "Round 16": {"Accuracy/Testing Accuracy": 0.43116883116883115, "Loss/Testing Loss": 2.140502678264271, "mean_training_loss": 0.13460236842677528}, "Round 17": {"Accuracy/Testing Accuracy": 0.4142857142857143, "Loss/Testing Loss": 2.152852275154807, "mean_training_loss": 0.20160638897077124}, "Round 18": {"Accuracy/Testing Accuracy": 0.4753246753246753, "Loss/Testing Loss": 1.9709687245356573, "mean_training_loss": 0.1246358274035932}, "Round 19": {"Accuracy/Testing Accuracy": 0.4623376623376623, "Loss/Testing Loss": 1.9578349633650347, "mean_training_loss": 0.10393628254532813}, "Round 20": {"Accuracy/Testing Accuracy": 0.4831168831168831, "Loss/Testing Loss": 1.9844564527660222, "mean_training_loss": 0.09131686756223001}, "Round 21": {"Accuracy/Testing Accuracy": 0.5077922077922078, "Loss/Testing Loss": 1.9193553134992525, "mean_training_loss": 0.0691809156277616}, "Round 22": {"Accuracy/Testing Accuracy": 0.561038961038961, "Loss/Testing Loss": 1.7494151313583572, "mean_training_loss": 0.11189095036126673}, "Round 23": {"Accuracy/Testing Accuracy": 0.561038961038961, "Loss/Testing Loss": 1.7101903949465072, "mean_training_loss": 0.13428057959924142}, "Round 24": {"Accuracy/Testing Accuracy": 0.5441558441558442, "Loss/Testing Loss": 1.6367229387357638, "mean_training_loss": 0.11967157056399932}, "Round 25": {"Accuracy/Testing Accuracy": 0.5428571428571428, "Loss/Testing Loss": 1.6448029103217188, "mean_training_loss": 0.12242974881415387}, "Round 26": {"Accuracy/Testing Accuracy": 0.5506493506493506, "Loss/Testing Loss": 1.6438123517222218, "mean_training_loss": 0.08727879544927016}, "Round 27": {"Accuracy/Testing Accuracy": 0.5402597402597402, "Loss/Testing Loss": 1.678114520110093, "mean_training_loss": 0.08859461623673828}, "Round 28": {"Accuracy/Testing Accuracy": 0.5792207792207792, "Loss/Testing Loss": 1.5451566878851357, "mean_training_loss": 0.1345868819966339}, "Round 29": {"Accuracy/Testing Accuracy": 0.5831168831168831, "Loss/Testing Loss": 1.5900042614379486, "mean_training_loss": 0.47103059705760747}, "Round 30": {"Accuracy/Testing Accuracy": 0.5428571428571428, "Loss/Testing Loss": 1.6619868139167884, "mean_training_loss": 0.17345218544692867}, "Round 31": {"Accuracy/Testing Accuracy": 0.5766233766233766, "Loss/Testing Loss": 1.6424874222123778, "mean_training_loss": 0.12103927692087987}, "Round 32": {"Accuracy/Testing Accuracy": 0.5831168831168831, "Loss/Testing Loss": 1.5282280955995833, "mean_training_loss": 0.07044469221817475}, "Round 33": {"Accuracy/Testing Accuracy": 0.5766233766233766, "Loss/Testing Loss": 1.5598749646892796, "mean_training_loss": 0.12402801838539101}, "Round 34": {"Accuracy/Testing Accuracy": 0.5636363636363636, "Loss/Testing Loss": 1.562340699233018, "mean_training_loss": 0.06846173114143313}, "Round 35": {"Accuracy/Testing Accuracy": 0.574025974025974, "Loss/Testing Loss": 1.5247585956152383, "mean_training_loss": 0.05352403250789003}, "Round 36": {"Accuracy/Testing Accuracy": 0.5948051948051948, "Loss/Testing Loss": 1.4473801352761009, "mean_training_loss": 0.10612778966980321}, "Round 37": {"Accuracy/Testing Accuracy": 0.6519480519480519, "Loss/Testing Loss": 1.3223459376917257, "mean_training_loss": 0.057822376385313234}, "Round 38": {"Accuracy/Testing Accuracy": 0.6571428571428571, "Loss/Testing Loss": 1.3043429897977161, "mean_training_loss": 0.03334678890398489}, "Round 39": {"Accuracy/Testing Accuracy": 0.6454545454545455, "Loss/Testing Loss": 1.2980607295965219, "mean_training_loss": 0.03266606784891338}, "Round 40": {"Accuracy/Testing Accuracy": 0.6519480519480519, "Loss/Testing Loss": 1.2925116752649282, "mean_training_loss": 0.0324094180940717}, "Round 41": {"Accuracy/Testing Accuracy": 0.6636363636363637, "Loss/Testing Loss": 1.270612736491414, "mean_training_loss": 0.04798752819381965}, "Round 42": {"Accuracy/Testing Accuracy": 0.6610389610389611, "Loss/Testing Loss": 1.2748032074470024, "mean_training_loss": 0.0516875025263289}, "Round 43": {"Accuracy/Testing Accuracy": 0.6571428571428571, "Loss/Testing Loss": 1.2459300762647159, "mean_training_loss": 0.06649849698335554}, "Round 44": {"Accuracy/Testing Accuracy": 0.6818181818181818, "Loss/Testing Loss": 1.1795823747461491, "mean_training_loss": 0.020764675006336934}, "Round 45": {"Accuracy/Testing Accuracy": 0.674025974025974, "Loss/Testing Loss": 1.2080916615275594, "mean_training_loss": 0.030815385710721944}, "Round 46": {"Accuracy/Testing Accuracy": 0.6792207792207792, "Loss/Testing Loss": 1.1987333328692944, "mean_training_loss": 0.05222505054687364}, "Round 47": {"Accuracy/Testing Accuracy": 0.6597402597402597, "Loss/Testing Loss": 1.2711334178974103, "mean_training_loss": 0.03588280151598155}, "Round 48": {"Accuracy/Testing Accuracy": 0.6311688311688312, "Loss/Testing Loss": 1.3436085936311004, "mean_training_loss": 0.0385688397155788}, "Round 49": {"Accuracy/Testing Accuracy": 0.6454545454545455, "Loss/Testing Loss": 1.3097237271147888, "mean_training_loss": 0.028163178206887095}, "Round 50": {"Accuracy/Testing Accuracy": 0.6662337662337663, "Loss/Testing Loss": 1.2474383546160412, "mean_training_loss": 0.03732457190053537}, "Round 51": {"Accuracy/Testing Accuracy": 0.6805194805194805, "Loss/Testing Loss": 1.1814703696733946, "mean_training_loss": 0.027437545026962957}, "Round 52": {"Accuracy/Testing Accuracy": 0.6623376623376623, "Loss/Testing Loss": 1.1947072171545647, "mean_training_loss": 0.018973123209240536}, "Round 53": {"Accuracy/Testing Accuracy": 0.6415584415584416, "Loss/Testing Loss": 1.2656566975952743, "mean_training_loss": 0.013278700427950494}, "Round 54": {"Accuracy/Testing Accuracy": 0.638961038961039, "Loss/Testing Loss": 1.2873537868648381, "mean_training_loss": 0.03658788252729349}, "Round 55": {"Accuracy/Testing Accuracy": 0.6441558441558441, "Loss/Testing Loss": 1.2414104950892462, "mean_training_loss": 0.028252721164996424}, "Round 56": {"Accuracy/Testing Accuracy": 0.6727272727272727, "Loss/Testing Loss": 1.1768914891527844, "mean_training_loss": 0.019268229354305992}, "Round 57": {"Accuracy/Testing Accuracy": 0.6844155844155844, "Loss/Testing Loss": 1.1897532490940836, "mean_training_loss": 0.06645929745198893}, "Round 58": {"Accuracy/Testing Accuracy": 0.6311688311688312, "Loss/Testing Loss": 1.27692710393435, "mean_training_loss": 0.06192746781744063}, "Round 59": {"Accuracy/Testing Accuracy": 0.6493506493506493, "Loss/Testing Loss": 1.247293936432182, "mean_training_loss": 0.7299717645027808}, "Round 60": {"Accuracy/Testing Accuracy": 0.6155844155844156, "Loss/Testing Loss": 1.373952408580037, "mean_training_loss": 0.013501482258240383}, "Round 61": {"Accuracy/Testing Accuracy": 0.6246753246753247, "Loss/Testing Loss": 1.3147943843494763, "mean_training_loss": 0.03697779428829173}, "Round 62": {"Accuracy/Testing Accuracy": 0.6636363636363637, "Loss/Testing Loss": 1.195182357825242, "mean_training_loss": 0.012818127039354296}, "Round 63": {"Accuracy/Testing Accuracy": 0.6636363636363637, "Loss/Testing Loss": 1.1589952406945168, "mean_training_loss": 0.4829625951556059}, "Round 64": {"Accuracy/Testing Accuracy": 0.6337662337662338, "Loss/Testing Loss": 1.253537385494678, "mean_training_loss": 0.0350557618890889}, "Round 65": {"Accuracy/Testing Accuracy": 0.6324675324675325, "Loss/Testing Loss": 1.2353895351484225, "mean_training_loss": 0.5047279873808079}, "Round 66": {"Accuracy/Testing Accuracy": 0.6376623376623377, "Loss/Testing Loss": 1.2355237824576242, "mean_training_loss": 0.035546628336765265}, "Round 67": {"Accuracy/Testing Accuracy": 0.6480519480519481, "Loss/Testing Loss": 1.2049051086623948, "mean_training_loss": 0.5031934983734236}, "Round 68": {"Accuracy/Testing Accuracy": 0.6402597402597403, "Loss/Testing Loss": 1.2540309299122203, "mean_training_loss": 0.04639087701901136}, "Round 69": {"Accuracy/Testing Accuracy": 0.6701298701298701, "Loss/Testing Loss": 1.1681818522416152, "mean_training_loss": 0.02741286302373434}, "Round 70": {"Accuracy/Testing Accuracy": 0.6922077922077922, "Loss/Testing Loss": 1.1430923074870916, "mean_training_loss": 0.08292324233489731}, "Round 71": {"Accuracy/Testing Accuracy": 0.6831168831168831, "Loss/Testing Loss": 1.139536081970512, "mean_training_loss": 0.03959732631260219}, "Round 72": {"Accuracy/Testing Accuracy": 0.6883116883116883, "Loss/Testing Loss": 1.0812774710840993, "mean_training_loss": 0.01513071241322905}, "Round 73": {"Accuracy/Testing Accuracy": 0.6857142857142857, "Loss/Testing Loss": 1.0906916299423615, "mean_training_loss": 0.023344390776603382}, "Round 74": {"Accuracy/Testing Accuracy": 0.6779220779220779, "Loss/Testing Loss": 1.1282418130280136, "mean_training_loss": 0.008632593448939067}, "Round 75": {"Accuracy/Testing Accuracy": 0.6987012987012987, "Loss/Testing Loss": 1.084102422540838, "mean_training_loss": 0.6129920897136132}, "Round 76": {"Accuracy/Testing Accuracy": 0.6857142857142857, "Loss/Testing Loss": 1.1132052071682819, "mean_training_loss": 0.024177862693821744}, "Round 77": {"Accuracy/Testing Accuracy": 0.7064935064935065, "Loss/Testing Loss": 1.0377832130952316, "mean_training_loss": 0.02004830638111076}, "Round 78": {"Accuracy/Testing Accuracy": 0.7025974025974026, "Loss/Testing Loss": 1.0400410358007852, "mean_training_loss": 0.021594193212401407}, "Round 79": {"Accuracy/Testing Accuracy": 0.7025974025974026, "Loss/Testing Loss": 1.0229285407375979, "mean_training_loss": 0.048010576380017614}, "Round 80": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.9831646414546223, "mean_training_loss": 0.014499680042568153}, "Round 81": {"Accuracy/Testing Accuracy": 0.7116883116883117, "Loss/Testing Loss": 1.0522902104761693, "mean_training_loss": 0.017290603113360704}, "Round 82": {"Accuracy/Testing Accuracy": 0.7155844155844155, "Loss/Testing Loss": 1.0053958911400336, "mean_training_loss": 0.013663666318349827}, "Round 83": {"Accuracy/Testing Accuracy": 0.674025974025974, "Loss/Testing Loss": 1.0839856417148144, "mean_training_loss": 0.013539123944272952}, "Round 84": {"Accuracy/Testing Accuracy": 0.6727272727272727, "Loss/Testing Loss": 1.0969033773843344, "mean_training_loss": 0.015113717512940638}, "Round 85": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 1.03293139810686, "mean_training_loss": 0.008309672175528249}, "Round 86": {"Accuracy/Testing Accuracy": 0.7142857142857143, "Loss/Testing Loss": 1.0129938218500707, "mean_training_loss": 0.012632891569020494}, "Round 87": {"Accuracy/Testing Accuracy": 0.6961038961038961, "Loss/Testing Loss": 1.0066573204932274, "mean_training_loss": 0.5848103616386652}, "Round 88": {"Accuracy/Testing Accuracy": 0.674025974025974, "Loss/Testing Loss": 1.1256534821027284, "mean_training_loss": 0.2198803481894235}, "Round 89": {"Accuracy/Testing Accuracy": 0.6909090909090909, "Loss/Testing Loss": 1.1175337553024292, "mean_training_loss": 0.02421780280186795}, "Round 90": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 1.052004505751969, "mean_training_loss": 0.07337456636263856}, "Round 91": {"Accuracy/Testing Accuracy": 0.7051948051948052, "Loss/Testing Loss": 1.0528080946439273, "mean_training_loss": 0.010915282398733933}, "Round 92": {"Accuracy/Testing Accuracy": 0.7064935064935065, "Loss/Testing Loss": 1.0467899110410122, "mean_training_loss": 0.012362092164888358}, "Round 93": {"Accuracy/Testing Accuracy": 0.7207792207792207, "Loss/Testing Loss": 1.0015151660163681, "mean_training_loss": 0.010608109673306058}, "Round 94": {"Accuracy/Testing Accuracy": 0.712987012987013, "Loss/Testing Loss": 1.0110281535557337, "mean_training_loss": 0.013575161110299331}, "Round 95": {"Accuracy/Testing Accuracy": 0.7142857142857143, "Loss/Testing Loss": 1.0207760077018242, "mean_training_loss": 0.011978100645743932}, "Round 96": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.9568495838673083, "mean_training_loss": 0.012071206015534701}, "Round 97": {"Accuracy/Testing Accuracy": 0.7155844155844155, "Loss/Testing Loss": 0.9945513842941879, "mean_training_loss": 0.20429492453695275}, "Round 98": {"Accuracy/Testing Accuracy": 0.7, "Loss/Testing Loss": 1.0113136399875988, "mean_training_loss": 0.15073347684855645}, "Round 99": {"Accuracy/Testing Accuracy": 0.7064935064935065, "Loss/Testing Loss": 0.9878821136115433, "mean_training_loss": 0.013118427240156702}, "Round 100": {"Accuracy/Testing Accuracy": 0.7116883116883117, "Loss/Testing Loss": 0.959217634758392, "mean_training_loss": 0.012410056545299343}, "Round 101": {"Accuracy/Testing Accuracy": 0.6974025974025974, "Loss/Testing Loss": 1.0401408474166671, "mean_training_loss": 0.0136888020968234}, "Round 102": {"Accuracy/Testing Accuracy": 0.7051948051948052, "Loss/Testing Loss": 1.0126840882487111, "mean_training_loss": 0.00973962153075263}, "Round 103": {"Accuracy/Testing Accuracy": 0.7090909090909091, "Loss/Testing Loss": 0.9856248973251938, "mean_training_loss": 0.011309594278379033}, "Round 104": {"Accuracy/Testing Accuracy": 0.7064935064935065, "Loss/Testing Loss": 1.0051128438540868, "mean_training_loss": 0.07293421425856651}, "Round 105": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9755601771466144, "mean_training_loss": 0.010503925556743827}, "Round 106": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.954207449609583, "mean_training_loss": 0.009228284804460902}, "Round 107": {"Accuracy/Testing Accuracy": 0.7272727272727273, "Loss/Testing Loss": 0.9479810392701781, "mean_training_loss": 0.046157300472707274}, "Round 108": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9583377989855679, "mean_training_loss": 0.22133708720977766}, "Round 109": {"Accuracy/Testing Accuracy": 0.7194805194805195, "Loss/Testing Loss": 1.0239728723253523, "mean_training_loss": 0.013268456286251812}, "Round 110": {"Accuracy/Testing Accuracy": 0.7155844155844155, "Loss/Testing Loss": 0.995102368701588, "mean_training_loss": 0.011185616845198509}, "Round 111": {"Accuracy/Testing Accuracy": 0.7207792207792207, "Loss/Testing Loss": 0.9647300757370986, "mean_training_loss": 0.0075677548531010485}, "Round 112": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.9546298181855833, "mean_training_loss": 0.012708919723601345}, "Round 113": {"Accuracy/Testing Accuracy": 0.7324675324675325, "Loss/Testing Loss": 0.9356420177917976, "mean_training_loss": 0.005337702154481252}, "Round 114": {"Accuracy/Testing Accuracy": 0.7298701298701299, "Loss/Testing Loss": 0.9467737204068667, "mean_training_loss": 0.010322487022494897}, "Round 115": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.9395990885697402, "mean_training_loss": 0.0055637945433294304}, "Round 116": {"Accuracy/Testing Accuracy": 0.7064935064935065, "Loss/Testing Loss": 1.0050240013506506, "mean_training_loss": 0.010893316925115264}, "Round 117": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9825664031041133, "mean_training_loss": 0.009793133229582704}, "Round 118": {"Accuracy/Testing Accuracy": 0.7077922077922078, "Loss/Testing Loss": 0.9766782687856005, "mean_training_loss": 0.005934670038914192}, "Round 119": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.9532060651036052, "mean_training_loss": 0.006277129962109029}, "Round 120": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 1.0063835794275457, "mean_training_loss": 0.005468369189683082}, "Round 121": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9961807743295447, "mean_training_loss": 0.010369138631914906}, "Round 122": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9978589503796069, "mean_training_loss": 0.011254084459894027}, "Round 123": {"Accuracy/Testing Accuracy": 0.7285714285714285, "Loss/Testing Loss": 0.9726898004482318, "mean_training_loss": 0.009489478396538359}, "Round 124": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.9991660774528206, "mean_training_loss": 0.00915733442691687}, "Round 125": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.9794400948982734, "mean_training_loss": 0.0164757687645033}, "Round 126": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.9325335319940146, "mean_training_loss": 0.009716217680501618}, "Round 127": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.9356952304963941, "mean_training_loss": 0.005175919020487191}, "Round 128": {"Accuracy/Testing Accuracy": 0.7220779220779221, "Loss/Testing Loss": 0.9389406808010944, "mean_training_loss": 0.004370126010487891}, "Round 129": {"Accuracy/Testing Accuracy": 0.7233766233766233, "Loss/Testing Loss": 0.9581519170240922, "mean_training_loss": 0.011085139980099887}, "Round 130": {"Accuracy/Testing Accuracy": 0.7259740259740259, "Loss/Testing Loss": 0.9669875271908649, "mean_training_loss": 0.009360653630158465}, "Round 131": {"Accuracy/Testing Accuracy": 0.7116883116883117, "Loss/Testing Loss": 1.0392601310432732, "mean_training_loss": 0.012050867580027052}, "Round 132": {"Accuracy/Testing Accuracy": 0.7311688311688311, "Loss/Testing Loss": 0.9746951864911364, "mean_training_loss": 0.36804390486384575}, "Round 133": {"Accuracy/Testing Accuracy": 0.6909090909090909, "Loss/Testing Loss": 1.0997956975713952, "mean_training_loss": 0.04135854743498688}, "Round 134": {"Accuracy/Testing Accuracy": 0.6974025974025974, "Loss/Testing Loss": 1.0777727511021997, "mean_training_loss": 0.13685945497395902}, "Round 135": {"Accuracy/Testing Accuracy": 0.7038961038961039, "Loss/Testing Loss": 1.0302903358038369, "mean_training_loss": 0.008945849655512057}, "Round 136": {"Accuracy/Testing Accuracy": 0.6805194805194805, "Loss/Testing Loss": 1.1286932570593697, "mean_training_loss": 0.006517537742232282}, "Round 137": {"Accuracy/Testing Accuracy": 0.6896103896103896, "Loss/Testing Loss": 1.1010706663131713, "mean_training_loss": 0.23044989569798896}, "Round 138": {"Accuracy/Testing Accuracy": 0.6922077922077922, "Loss/Testing Loss": 1.107921357897969, "mean_training_loss": 0.015874960365741014}, "Round 139": {"Accuracy/Testing Accuracy": 0.6766233766233766, "Loss/Testing Loss": 1.154851517119965, "mean_training_loss": 0.014116930263116955}, "Round 140": {"Accuracy/Testing Accuracy": 0.6831168831168831, "Loss/Testing Loss": 1.0968560921681392, "mean_training_loss": 0.0062889279994124084}}